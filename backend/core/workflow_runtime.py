import re
import json
import random
import string
import asyncio
from typing import Any, Dict, List, Optional, Set, Callable, Awaitable
from pydantic import BaseModel
from enum import Enum

# --- Data Structures ---


class NodeExecutionStatus(str, Enum):
    """节点执行状态"""
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    SKIPPED = "skipped"
    FAILED = "failed"


class WorkflowEdge(BaseModel):
    """工作流边（连接）"""
    id: str
    source_node_id: str
    target_node_id: str
    source_handle: Optional[str] = None  # 源节点的输出端口 (e.g., 'true', 'false', 'default')
    target_handle: Optional[str] = None  # 目标节点的输入端口
    condition: Optional[str] = None      # 边的条件表达式


class WorkflowNode(BaseModel):
    id: str
    type: str  # e.g., 'start', 'trigger', 'action_send_email', 'tool_random_string'
    label: str
    config: Dict[str, Any] = {}
    next_node_id: Optional[str] = None  # 保留向后兼容
    # 新增：支持多输出端口
    output_handles: List[str] = []  # e.g., ['true', 'false'] for condition nodes


class WorkflowDefinition(BaseModel):
    id: str
    name: str
    nodes: Dict[str, WorkflowNode]  # Key is node_id
    start_node_id: str
    edges: List[WorkflowEdge] = []  # 新增：边列表


# --- Runtime Context ---

class WorkflowContext:
    """
    Holds the state of a running workflow.
    Everything that happens is stored here.
    """
    def __init__(self, trigger_data: Dict[str, Any]):
        self.data: Dict[str, Any] = {
            "trigger": trigger_data,  # Constant data from the event
            "steps": {},              # Dynamic data generated by nodes
            "global": {},             # System global variables
        }
        self.variables: Dict[str, Any] = {}  # 兼容旧接口
        self._node_outputs: Dict[str, str] = {}  # 节点输出端口: node_id -> handle

    def set_step_output(self, node_id: str, output: Any):
        """Save the result of a node execution."""
        self.data["steps"][node_id] = output
        # 同时更新 variables 以保持兼容
        if isinstance(output, dict):
            for key, value in output.items():
                self.variables[f"{node_id}.{key}"] = value

    def set_node_output_handle(self, node_id: str, handle: str):
        """记录节点选择的输出端口（用于条件分支）"""
        self._node_outputs[node_id] = handle

    def get_node_output_handle(self, node_id: str) -> Optional[str]:
        """获取节点选择的输出端口"""
        return self._node_outputs.get(node_id)

    def get_value(self, path: str) -> Any:
        """
        Retrieve a value using dot notation.
        e.g., "trigger.user.email" -> self.data["trigger"]["user"]["email"]
        """
        parts = path.split('.')
        current = self.data

        try:
            for part in parts:
                if isinstance(current, dict) and part in current:
                    current = current[part]
                else:
                    return None  # Path not found
            return current
        except Exception:
            return None

    def get_variable(self, name: str, default: Any = None) -> Any:
        """获取变量值（兼容旧接口）"""
        # 先尝试新格式
        result = self.get_value(name)
        if result is not None:
            return result
        # 再尝试 variables
        return self.variables.get(name, default)

    def set_variable(self, name: str, value: Any):
        """设置变量值（兼容旧接口）"""
        self.variables[name] = value


# --- Variable Resolver ---

class VariableResolver:
    """
    The magic class that converts "{{variable}}" into real values.
    """

    @staticmethod
    def resolve(template: Any, context: WorkflowContext) -> Any:
        """
        Recursively resolves variables in dictionaries, lists, and strings.
        """
        # Case 1: Dict -> Recursively resolve values
        if isinstance(template, dict):
            return {k: VariableResolver.resolve(v, context) for k, v in template.items()}

        # Case 2: List -> Recursively resolve items
        if isinstance(template, list):
            return [VariableResolver.resolve(item, context) for item in template]

        # Case 3: String -> Check for {{...}} patterns
        if isinstance(template, str):
            # Pattern 1: Exact Match (e.g. "{{trigger.count}}") -> Return actual type (int/obj/etc)
            strict_pattern = r'^\{\{([\w\.]+)\}\}$'
            match = re.match(strict_pattern, template.strip())
            if match:
                path = match.group(1)
                val = context.get_value(path)
                # If value is found, return it (preserving type); otherwise return original string
                return val if val is not None else template

            # Pattern 2: Interpolation (e.g. "Hello {{trigger.name}}") -> Return string
            def replace_func(m):
                path = m.group(1)
                val = context.get_value(path)
                return str(val) if val is not None else m.group(0)

            if '{{' in template:
                return re.sub(r'\{\{([\w\.]+)\}\}', replace_func, template)

        # Case 4: Primitives -> Return as is
        return template


# --- Graph Executor ---

class GraphExecutor:
    """
    图遍历执行器
    支持条件分支、并行执行等复杂流程
    """

    def __init__(self, definition: WorkflowDefinition):
        self.definition = definition
        self._build_graph()

    def _build_graph(self):
        """构建邻接表"""
        # node_id -> [(target_node_id, source_handle, condition)]
        self.adjacency: Dict[str, List[tuple]] = {}
        # 入度统计（用于检测起始节点）
        self.in_degree: Dict[str, int] = {node_id: 0 for node_id in self.definition.nodes}

        for edge in self.definition.edges:
            if edge.source_node_id not in self.adjacency:
                self.adjacency[edge.source_node_id] = []
            self.adjacency[edge.source_node_id].append((
                edge.target_node_id,
                edge.source_handle,
                edge.condition
            ))
            self.in_degree[edge.target_node_id] = self.in_degree.get(edge.target_node_id, 0) + 1

        # 同时支持旧版 next_node_id
        for node_id, node in self.definition.nodes.items():
            if node.next_node_id and node_id not in self.adjacency:
                self.adjacency[node_id] = [(node.next_node_id, None, None)]
                self.in_degree[node.next_node_id] = self.in_degree.get(node.next_node_id, 0) + 1

    def get_next_nodes(self, node_id: str, context: WorkflowContext) -> List[str]:
        """
        获取下一步要执行的节点
        根据当前节点的输出端口和边的条件来决定
        """
        edges = self.adjacency.get(node_id, [])
        if not edges:
            return []

        output_handle = context.get_node_output_handle(node_id)
        next_nodes = []

        for target_id, source_handle, condition in edges:
            # 如果边指定了 source_handle，需要匹配节点的输出
            if source_handle is not None:
                if output_handle != source_handle:
                    continue  # 不匹配，跳过这条边

            # 如果有条件表达式，评估条件
            if condition:
                if not self._evaluate_condition(condition, context):
                    continue

            next_nodes.append(target_id)

        return next_nodes

    def _evaluate_condition(self, condition: str, context: WorkflowContext) -> bool:
        """评估条件表达式"""
        try:
            # 简单实现：替换变量后 eval
            resolved = VariableResolver.resolve(condition, context)
            if isinstance(resolved, bool):
                return resolved
            if isinstance(resolved, str):
                # 安全评估简单布尔表达式
                return resolved.lower() in ('true', 'yes', '1')
            return bool(resolved)
        except Exception:
            return False


# --- The Engine (Upgraded) ---

class WorkflowEngine:
    """
    升级版工作流引擎
    支持：
    - 线性流程（兼容旧版）
    - 条件分支（通过输出端口）
    - 并行执行（同一层级的多个节点）
    - 错误处理和恢复
    """

    def __init__(self, workflow: WorkflowDefinition, handlers: Dict[str, Any] = None):
        self.workflow = workflow
        self.handlers = handlers or {}
        self.executor = GraphExecutor(workflow)
        self._executed_nodes: Set[str] = set()  # 防止重复执行

    async def run(self, trigger_data: Dict[str, Any]) -> WorkflowContext:
        """
        The main execution loop.
        支持图遍历，处理分支和并行。
        """
        context = WorkflowContext(trigger_data)

        print(f"\n[ENGINE] Starting Workflow: {self.workflow.name}")
        print(f"[ENGINE] Trigger Data: {json.dumps(trigger_data, default=str)}")

        # 使用 BFS 遍历执行
        queue: List[str] = [self.workflow.start_node_id]

        while queue:
            # 获取当前层级的所有节点
            current_level = queue.copy()
            queue.clear()

            # 并行执行当前层级的节点
            if len(current_level) == 1:
                # 单节点，直接执行
                node_id = current_level[0]
                await self._execute_single_node(node_id, context)
                next_nodes = self.executor.get_next_nodes(node_id, context)
                for next_id in next_nodes:
                    if next_id not in self._executed_nodes:
                        queue.append(next_id)
            else:
                # 多节点，并行执行
                tasks = [
                    self._execute_single_node(node_id, context)
                    for node_id in current_level
                    if node_id not in self._executed_nodes
                ]
                await asyncio.gather(*tasks)

                # 收集所有下一步节点
                for node_id in current_level:
                    next_nodes = self.executor.get_next_nodes(node_id, context)
                    for next_id in next_nodes:
                        if next_id not in self._executed_nodes and next_id not in queue:
                            queue.append(next_id)

        print("\n[ENGINE] Workflow Finished Successfully.")
        return context

    async def _execute_single_node(self, node_id: str, context: WorkflowContext) -> Optional[Dict]:
        """执行单个节点"""
        if node_id in self._executed_nodes:
            return None

        node = self.workflow.nodes.get(node_id)
        if not node:
            print(f"[ENGINE] Error: Node {node_id} not found. Skipping.")
            return None

        self._executed_nodes.add(node_id)
        print(f"\n>> Executing Node: [{node.label}] ({node.type})")

        # 1. Resolve Config: Turn {{variables}} into real values
        resolved_config = VariableResolver.resolve(node.config, context)

        # 2. Execute Logic: Call the specific handler
        result = await self.execute_node(node.type, resolved_config, context)

        # 3. Process result
        output = result
        output_handle = None

        # 处理节点返回格式
        if isinstance(result, tuple):
            # 旧格式: (success, output_data, next_handle)
            if len(result) == 3:
                _, output, output_handle = result
            elif len(result) == 2:
                _, output = result
        elif isinstance(result, dict):
            output = result
            # 检查是否有 _output_handle 字段
            output_handle = result.pop('_output_handle', None)

        # 4. Save Output: Store result in context
        context.set_step_output(node_id, output)
        if output_handle:
            context.set_node_output_handle(node_id, output_handle)
        print(f"   Output Saved to 'steps.{node_id}': {output}")

        return output

    async def execute_node(self, node_type: str, config: Dict[str, Any], context: WorkflowContext):
        """
        Executes a node by calling a registered handler.
        This keeps the engine pure and decouples it from specific business logic.
        """
        # 特殊节点类型
        if node_type in ('start', 'trigger', 'trigger_email_received', 'trigger_manual'):
            return {"status": "started"}

        if node_type in ('end', 'end_success', 'end_error'):
            return {"status": "ended", "message": config.get('message', 'Workflow ended')}

        handler = self.handlers.get(node_type)
        if not handler:
            print(f"[ENGINE] Warning: No handler registered for node type '{node_type}'")
            return None

        try:
            # Handle both async and sync handlers
            if asyncio.iscoroutinefunction(handler):
                return await handler(config, context)
            else:
                return handler(config, context)
        except Exception as e:
            print(f"[ENGINE] Error executing node {node_type}: {str(e)}")
            raise e